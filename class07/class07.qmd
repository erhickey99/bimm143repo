---
title: "Class 07: Machine Learning"
author: "Emily Hickey (A15575724)"
format: html
---

## Clustering

We will start today's lab with clustering methods, in particular so-called K-means. The main function for this in R is `kmeans()`.

Let's try it on some made up data where we know what the answer should be.

```{r}
x <- rnorm(10000, mean = 3)
hist(x)
```
60 points
```{r}
tmp <- c(rnorm(30, mean = 3), rnorm(30, -3))
x <- cbind(x=tmp, y=rev(tmp))
head(x)
```
We can pass this to the base R `plot()` function for a quick.

```{r}
plot(x)
```
```{r}
k <- kmeans(x, centers = 2, nstart = 20)
k
```

>Q1. How many points are in each cluster?

```{r}
k$size
```
>Q2. Cluster membership?

```{r}
k$cluster
```

>Q3. Cluster centers?

```{r}
k$centers
```

>Q4. Plot my clustering results

```{r}
plot(x, col=k$cluster, pch=16)
```
>Q5. Cluster the data again with k(means) into 4 groups and plot the results.

```{r}
k4 <- kmeans(x, centers = 4, nstart = 20)
plot(x, col=k4$cluster, pch=16)
```

K-means is very popular mostly because it is fast and relatively straightforward to run and understand. It has a big limitation in that you need to tell it how many groups (k, or centers) you want.

## Hierarchical clustering

The main function in base R is called `hclust()`. You have to pass it in a "distance matrix" not just your input data.

You can generate a distance matrix with the `dist()` function.
```{r}
hc <- hclust(dist(x))
hc
```

To find the clusters (cluster membership vector) from a `hclust()` result we can "cut" the tree at a certain height that we like.
```{r}
plot(hc)
abline(h=8, col="red")
grps <- cutree(hc,h=8)
```
```{r}
table(grps)
```
> Q6. Plot our hclust results.

```{r}
plot(x, col=grps, pch=16)
```

## Principal Component Analysis

#PCA of UK food data

Read data showing the consumption in grams (per person, per week) of 17 different types of foodstuff measured and averaged in the four countries of the United Kingdom in 1997.

Let's see how PCA can help us but first we can try conventional analysis.

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url)
```

#Note how the minus indexing works

```{r}
rownames(x) <- x[,1]
x <- x[,-1]
head(x)
```

>Q1. How many rows and columns are in your new data frame named x? What R functions could you use to answer this questions?

```{r}
dim(x)
nrow(x)
ncol(x)
```

```{r}
x <- read.csv(url, row.names = 1)
head(x)
```
>Q2. Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

I prefer the `row.names` function. When you run the code block x<- x[,-1] over and over again, columns begin to be omitted from the the data set.

```{r}
barplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))
```

>Q3: Changing what optional argument in the above barplot() function results in the following plot?

```{r}
barplot(as.matrix(x), beside=FALSE, col=rainbow(nrow(x)))
```

```{r}
pairs(x, col=rainbow(10), pch=16)
```

>Q5: Generating all pairwise plots may help somewhat. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?

The function `pairs()` "contains x[, i] plotted against x[,j], where x in this case represents the data of the 17 observations (food groups) and 4 variables (countries)." This means as we move to the right, England is our Y axis being plotted against Wales, Scotland and N. Ireland respectively. If a given point lies on the diagonal for a given plot, it means the values for both countries are the same.

## Principal Component Analysis (PCA)

PCA can help us make sense of these types of datasets. Let's see how it works.

The main function in "base" R is called `prcomp()`

```{r}
head(t(x))
```

>Q6. What is the main differences between N. Ireland and the other countries of the UK in terms of this data-set?

The main differences between N. Ireland and the other countries of the UK in terms of this data-set is that N. Ireland consumes significantly more fresh potatoes and less fresh fruit and alcoholic beverages. 

```{r}
pca <- prcomp( t(x) )
summary(pca)
```

```{r}
pca$x
```

>Q7. Complete the code below to generate a plot of PC1 vs PC2. The second line adds text labels over the data points.

```{r}
# Plot PC1 vs PC2

plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
text(pca$x[,1], pca$x[,2], colnames(x))
```


```{r}
plot(pca$x[,1], pca$x[,2], col=c("orange", "red", "blue", "darkgreen"), pch=16)
```

>Q8. Customize your plot so that the colors of the country names match the colors in our UK and Ireland map and table at start of this document.

```{r}
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
text(pca$x[,1], pca$x[,2], colnames(x),col =c("red", "orange","blue", "darkgreen"))
```

```{r}
v <- round(pca$sdev^2/sum(pca$sdev^2)*100)
v
```

```{r}
## or the second row here...
z <- summary(pca)
z$importance
```

```{r}
barplot(v, xlab="Principal Component", ylab="Percent Variation")
```


The "loadings" tells us how much the original variables (in our case the foods) contribute to the new variables i.e. the PCs

```{r}
head(pca$rotation)

##Lets focus on PC1 as it accounts for > 90% of variance

par(mar=c(10,3,0.35,0))
barplot(pca$rotation[,1], las=2)
```

>Q9: Generate a similar ‘loadings plot’ for PC2. What two food groups feature prominantely and what does PC2 maninly tell us about?

```{r}
par(mar=c(10,3,0.35,0))
barplot(pca$rotation[,2], las=2)
```

PC2 mainly tells us about Scotland and Wales. Wales consumes more fresh potatoes and Scotland consumes more soft drinks. 